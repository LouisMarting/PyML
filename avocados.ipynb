{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-screen",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To add a new cell, type '# %%'\n",
    "# To add a new markdown cell, type '# %% [markdown]'\n",
    "# %%\n",
    "from IPython import get_ipython\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# %%\n",
    "import itertools\n",
    "import functools\n",
    "\n",
    "class PolynomialFeature(object):\n",
    "    \"\"\"\n",
    "    polynomial features\n",
    "\n",
    "    transforms input array with polynomial features\n",
    "\n",
    "    Example\n",
    "    =======\n",
    "    x =\n",
    "    [[a, b],\n",
    "    [c, d]]\n",
    "\n",
    "    y = PolynomialFeatures(degree=2).transform(x)\n",
    "    y =\n",
    "    [[1, a, b, a^2, a * b, b^2],\n",
    "    [1, c, d, c^2, c * d, d^2]]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, degree=1):\n",
    "        \"\"\"\n",
    "        construct polynomial features\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        degree : int\n",
    "            degree of polynomial\n",
    "        \"\"\"\n",
    "        assert isinstance(degree, int)\n",
    "        self.degree = degree\n",
    "\n",
    "    def transform(self, x):\n",
    "        \"\"\"\n",
    "        transforms input array with polynomial features\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : (sample_size, n) ndarray\n",
    "            input array\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        output : (sample_size, 1 + nC1 + ... + nCd) ndarray\n",
    "            polynomial features\n",
    "        \"\"\"\n",
    "        if x.ndim == 1:\n",
    "            x = x[:, None]\n",
    "        x_t = x.transpose()\n",
    "        features = [np.ones(len(x))]\n",
    "        for degree in range(1, self.degree + 1):\n",
    "            for items in itertools.combinations_with_replacement(x_t, degree):\n",
    "                features.append(functools.reduce(lambda x, y: x * y, items))\n",
    "        return np.asarray(features).transpose()\n",
    "\n",
    "\n",
    "# %%\n",
    "class LinearRegression():\n",
    "    \"\"\"\n",
    "    Linear regression model\n",
    "    y = X @ w\n",
    "    t ~ N(t|X @ w, var)\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X:np.ndarray, t:np.ndarray):\n",
    "        \"\"\"\n",
    "        perform least squares fitting\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : (N, D) np.ndarray\n",
    "            training independent variable\n",
    "        t : (N,) np.ndarray\n",
    "            training dependent variable\n",
    "        \"\"\"\n",
    "        self.w = np.linalg.pinv(X) @ t\n",
    "        self.var = np.mean(np.square(X @ self.w - t))\n",
    "\n",
    "    def predict(self, X:np.ndarray, return_std:bool=False):\n",
    "        \"\"\"\n",
    "        make prediction given input\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : (N, D) np.ndarray\n",
    "            samples to predict their output\n",
    "        return_std : bool, optional\n",
    "            returns standard deviation of each prediction if True\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : (N,) np.ndarray\n",
    "            prediction of each sample\n",
    "        y_std : (N,) np.ndarray\n",
    "            standard deviation of each prediction\n",
    "        \"\"\"\n",
    "        y = X @ self.w\n",
    "        if return_std:\n",
    "            y_std = np.sqrt(self.var) + np.zeros_like(y)\n",
    "            return y, y_std\n",
    "        return y\n",
    "\n",
    "\n",
    "# %%\n",
    "class BayesianRegression():\n",
    "    \"\"\"\n",
    "    Bayesian regression model\n",
    "\n",
    "    w ~ N(w|0, alpha^(-1)I)\n",
    "    y = X @ w\n",
    "    t ~ N(t|X @ w, beta^(-1))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha:float=1., beta:float=1.):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.w_mean = None\n",
    "        self.w_precision = None\n",
    "\n",
    "    def _is_prior_defined(self) -> bool:\n",
    "        return self.w_mean is not None and self.w_precision is not None\n",
    "\n",
    "    def _get_prior(self, ndim:int) -> tuple:\n",
    "        if self._is_prior_defined():\n",
    "            return self.w_mean, self.w_precision\n",
    "        else:\n",
    "            return np.zeros(ndim), self.alpha * np.eye(ndim)\n",
    "\n",
    "    def fit(self, X:np.ndarray, t:np.ndarray):\n",
    "        \"\"\"\n",
    "        bayesian update of parameters given training dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : (N, n_features) np.ndarray\n",
    "            training data independent variable\n",
    "        t : (N,) np.ndarray\n",
    "            training data dependent variable\n",
    "        \"\"\"\n",
    "\n",
    "        mean_prev, precision_prev = self._get_prior(np.size(X, 1))\n",
    "\n",
    "        w_precision = precision_prev + self.beta * X.T @ X\n",
    "        w_mean = np.linalg.solve(\n",
    "            w_precision,\n",
    "            precision_prev @ mean_prev + self.beta * X.T @ t\n",
    "        )\n",
    "        self.w_mean = w_mean\n",
    "        self.w_precision = w_precision\n",
    "        self.w_cov = np.linalg.inv(self.w_precision)\n",
    "\n",
    "    def predict(self, X:np.ndarray, return_std:bool=False, sample_size:int=None):\n",
    "        \"\"\"\n",
    "        return mean (and standard deviation) of predictive distribution\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : (N, n_features) np.ndarray\n",
    "            independent variable\n",
    "        return_std : bool, optional\n",
    "            flag to return standard deviation (the default is False)\n",
    "        sample_size : int, optional\n",
    "            number of samples to draw from the predictive distribution\n",
    "            (the default is None, no sampling from the distribution)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y : (N,) np.ndarray\n",
    "            mean of the predictive distribution\n",
    "        y_std : (N,) np.ndarray\n",
    "            standard deviation of the predictive distribution\n",
    "        y_sample : (N, sample_size) np.ndarray\n",
    "            samples from the predictive distribution\n",
    "        \"\"\"\n",
    "\n",
    "        if sample_size is not None:\n",
    "            w_sample = np.random.multivariate_normal(\n",
    "                self.w_mean, self.w_cov, size=sample_size\n",
    "            )\n",
    "            y_sample = X @ w_sample.T\n",
    "            return y_sample\n",
    "        y = X @ self.w_mean\n",
    "        if return_std:\n",
    "            y_var = 1 / self.beta + np.sum(X @ self.w_cov * X, axis=1)\n",
    "            y_std = np.sqrt(y_var)\n",
    "            return y, y_std\n",
    "        return y\n",
    "\n",
    "\n",
    "\n",
    "    def _log_likelihood(self, X, t, w):\n",
    "        return -0.5 * self.beta * np.square(t - X @ w).sum()\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "avocado_df = pd.read_csv('avocado.csv')\n",
    "del avocado_df[\"Unnamed: 0\"]\n",
    "\n",
    "\n",
    "# %%\n",
    "avocado_df.info()\n",
    "\n",
    "\n",
    "# %%\n",
    "avocado_df.describe()\n",
    "\n",
    "\n",
    "# %%\n",
    "avocado_df.head(10)\n",
    "\n",
    "\n",
    "# %%\n",
    "#Scatter plot of the data\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "scatter_matrix(avocado_df,figsize = (13,13))\n",
    "print('The correlation matrix:')\n",
    "corr_mtx = avocado_df.corr()\n",
    "corr_mtx.round(2)\n",
    "\n",
    "\n",
    "# %%\n",
    "col_mapping = [f\"{c[0]}:{c[1]}\" for c in enumerate(avocado_df.columns)]\n",
    "col_mapping_dict = {c[0]:c[1] for c in enumerate(avocado_df.columns)}\n",
    "\n",
    "\n",
    "# %%\n",
    "print(col_mapping)\n",
    "\n",
    "\n",
    "# %%\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "avocado_array = avocado_df.iloc[:,1:10].to_numpy()\n",
    "X,y = avocado_array[:,1:],avocado_array[:,0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "print(X.shape,y.shape,X_train.shape, y_train.shape, X_test.shape, y_test.shape )\n",
    "\n",
    "\n",
    "# %%\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# standarization\n",
    "std_trans = StandardScaler()\n",
    "X_train = std_trans.fit_transform(X_train)\n",
    "X_test = std_trans.transform(X_test)\n",
    "\n",
    "\n",
    "# %%\n",
    "feature = PolynomialFeature(degree=1)\n",
    "X_train1, X_test1 = feature.transform(X_train), feature.transform(X_test)\n",
    "Linear = LinearRegression()\n",
    "Linear.fit(X_train1, y_train)\n",
    "errors_linear = mean_squared_error(Linear.predict(X_test1),y_test)\n",
    "\n",
    "Bayes = BayesianRegression(alpha=1., beta=100.)\n",
    "errors_bayes = []\n",
    "\n",
    "for idx in range(X_train1.shape[0]):\n",
    "    Bayes.fit(X_train1[idx:idx+1], y_train[idx:idx+1])\n",
    "    errors_bayes.append(mean_squared_error(Bayes.predict(X_test1),y_test))\n",
    "\n",
    "    \n",
    "plt.plot(errors_bayes,  'r', label = 'Bayesian Regression' ,linewidth = 2.)\n",
    "plt.plot([errors_linear]*X_train1.shape[0], 'b:', label = 'Linear Regression')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Validation MSE')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# %%\n",
    "#test comments \n",
    "\n",
    "\n",
    "# %%"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
